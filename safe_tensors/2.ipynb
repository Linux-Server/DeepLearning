{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(in_features=2, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer.weight', tensor([[0.5406, 0.5869]])),\n",
       "             ('layer.bias', tensor([-0.1657]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = MyModel()\n",
    "save_file(model.state_dict(), \"model.safetensors\")\n",
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer.bias': tensor([-0.1657]), 'layer.weight': tensor([[0.5406, 0.5869]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "test_model = MyModel() \n",
    "\n",
    "weights = load_file(\"./model.safetensors\")\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer.weight', tensor([[0.5406, 0.5869]])),\n",
       "             ('layer.bias', tensor([-0.1657]))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : layer.bias  and tensor: tensor([-0.1657])\n",
      "Name : layer.weight  and tensor: tensor([[0.5406, 0.5869]])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "with safe_open(\"model.safetensors\", framework=\"pt\") as f:\n",
    "    for i in f.keys():\n",
    "        print(f\"Name : {i}  and tensor: {f.get_tensor(i)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5406, 0.5869]])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "with safe_open(\"model.safetensors\", framework=\"pt\") as f:\n",
    "    print(f.get_tensor(\"layer.weight\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded safetensors 0:00:00.000981\n",
      "Loaded pytorch 0:00:00.002020\n",
      "on CPU, safetensors is faster than pytorch by: 2.1 X\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "import torch\n",
    "\n",
    "start_st = datetime.datetime.now()\n",
    "weights = load_file(\"./model.safetensors\", device=\"cpu\")\n",
    "load_time_st = datetime.datetime.now() - start_st\n",
    "print(f\"Loaded safetensors {load_time_st}\")\n",
    "\n",
    "start_pt = datetime.datetime.now()\n",
    "weights = torch.load(\"./model.pt\", map_location=\"cpu\")\n",
    "load_time_pt = datetime.datetime.now() - start_pt\n",
    "print(f\"Loaded pytorch {load_time_pt}\")\n",
    "\n",
    "print(f\"on CPU, safetensors is faster than pytorch by: {load_time_pt/load_time_st:.1f} X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'a.weight': tensor([[-0.0487,  0.0587,  0.0882,  ..., -0.0726,  0.0023, -0.0683],\n",
      "        [-0.0848, -0.0551, -0.0875,  ...,  0.0390, -0.0050, -0.0603],\n",
      "        [-0.0612, -0.0896, -0.0326,  ..., -0.0479, -0.0814,  0.0839],\n",
      "        ...,\n",
      "        [ 0.0407,  0.0201,  0.0366,  ...,  0.0722,  0.0103,  0.0911],\n",
      "        [ 0.0532,  0.0534, -0.0858,  ..., -0.0748,  0.0761, -0.0996],\n",
      "        [-0.0037, -0.0617, -0.0421,  ..., -0.0585,  0.0528, -0.0033]]), 'a.bias': tensor([-0.0918,  0.0981,  0.0261,  0.0920,  0.0125,  0.0143,  0.0721, -0.0680,\n",
      "         0.0944, -0.0643,  0.0091, -0.0650, -0.0663,  0.0770, -0.0264, -0.0188,\n",
      "         0.0781,  0.0980, -0.0902, -0.0017,  0.0286,  0.0960, -0.0399, -0.0325,\n",
      "        -0.0586,  0.0256,  0.0247, -0.0016, -0.0101, -0.0696, -0.0411, -0.0380,\n",
      "         0.0263,  0.0442,  0.0467, -0.0763, -0.0077, -0.0191,  0.0997,  0.0722,\n",
      "        -0.0746, -0.0549, -0.0755, -0.0250, -0.0875,  0.0470, -0.0441, -0.0502,\n",
      "         0.0047, -0.0320,  0.0755,  0.0906, -0.0893,  0.0448,  0.0021,  0.0525,\n",
      "        -0.0375, -0.0076, -0.0019,  0.0343,  0.0499,  0.0390,  0.0123, -0.0798,\n",
      "        -0.0574, -0.0570, -0.0997,  0.0958, -0.0453, -0.0665, -0.0453,  0.0543,\n",
      "        -0.0627, -0.0836, -0.0747,  0.0220, -0.0041, -0.0902, -0.0684, -0.0867,\n",
      "         0.0343,  0.0453,  0.0170, -0.0320, -0.0536,  0.0395, -0.0230, -0.0161,\n",
      "        -0.0328,  0.0174,  0.0235,  0.0822,  0.0888, -0.0258,  0.0149, -0.0668,\n",
      "        -0.0751,  0.0829,  0.0118, -0.0497]), 'b.weight': tensor([[-0.0487,  0.0587,  0.0882,  ..., -0.0726,  0.0023, -0.0683],\n",
      "        [-0.0848, -0.0551, -0.0875,  ...,  0.0390, -0.0050, -0.0603],\n",
      "        [-0.0612, -0.0896, -0.0326,  ..., -0.0479, -0.0814,  0.0839],\n",
      "        ...,\n",
      "        [ 0.0407,  0.0201,  0.0366,  ...,  0.0722,  0.0103,  0.0911],\n",
      "        [ 0.0532,  0.0534, -0.0858,  ..., -0.0748,  0.0761, -0.0996],\n",
      "        [-0.0037, -0.0617, -0.0421,  ..., -0.0585,  0.0528, -0.0033]]), 'b.bias': tensor([-0.0918,  0.0981,  0.0261,  0.0920,  0.0125,  0.0143,  0.0721, -0.0680,\n",
      "         0.0944, -0.0643,  0.0091, -0.0650, -0.0663,  0.0770, -0.0264, -0.0188,\n",
      "         0.0781,  0.0980, -0.0902, -0.0017,  0.0286,  0.0960, -0.0399, -0.0325,\n",
      "        -0.0586,  0.0256,  0.0247, -0.0016, -0.0101, -0.0696, -0.0411, -0.0380,\n",
      "         0.0263,  0.0442,  0.0467, -0.0763, -0.0077, -0.0191,  0.0997,  0.0722,\n",
      "        -0.0746, -0.0549, -0.0755, -0.0250, -0.0875,  0.0470, -0.0441, -0.0502,\n",
      "         0.0047, -0.0320,  0.0755,  0.0906, -0.0893,  0.0448,  0.0021,  0.0525,\n",
      "        -0.0375, -0.0076, -0.0019,  0.0343,  0.0499,  0.0390,  0.0123, -0.0798,\n",
      "        -0.0574, -0.0570, -0.0997,  0.0958, -0.0453, -0.0665, -0.0453,  0.0543,\n",
      "        -0.0627, -0.0836, -0.0747,  0.0220, -0.0041, -0.0902, -0.0684, -0.0867,\n",
      "         0.0343,  0.0453,  0.0170, -0.0320, -0.0536,  0.0395, -0.0230, -0.0161,\n",
      "        -0.0328,  0.0174,  0.0235,  0.0822,  0.0888, -0.0258,  0.0149, -0.0668,\n",
      "        -0.0751,  0.0829,  0.0118, -0.0497])})\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(100, 100)\n",
    "        self.b = self.a\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.b(self.a(x))\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(model.state_dict())\n",
    "# odict_keys(['a.weight', 'a.bias', 'b.weight', 'b.bias'])\n",
    "torch.save(model.state_dict(), \"model.bin\")\n",
    "# This file is now 41k instead of ~80k, because A and B are the same weight hence only 1 is saved on disk with both `a` and `b` pointing to the same buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10100"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(param.numel() for param in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parse safetensors files: 100%|██████████| 72/72 [00:04<00:00, 16.60it/s]\n"
     ]
    },
    {
     "ename": "NotASafetensorsRepoError",
     "evalue": "'runwayml/stable-diffusion-v1-5' is not a safetensors repo. Couldn't find 'model.safetensors.index.json' or 'model.safetensors' files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotASafetensorsRepoError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m metadata\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mlen\u001b[39m(metadata\u001b[38;5;241m.\u001b[39mfiles_metadata)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mget_safetensors_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrunwayml/stable-diffusion-v1-5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers/lib/python3.13/site-packages/huggingface_hub/hf_api.py:5502\u001b[0m, in \u001b[0;36mHfApi.get_safetensors_metadata\u001b[0;34m(self, repo_id, repo_type, revision, token)\u001b[0m\n\u001b[1;32m   5494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SafetensorsRepoMetadata(\n\u001b[1;32m   5495\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   5496\u001b[0m         sharded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   5497\u001b[0m         weight_map\u001b[38;5;241m=\u001b[39mweight_map,\n\u001b[1;32m   5498\u001b[0m         files_metadata\u001b[38;5;241m=\u001b[39mfiles_metadata,\n\u001b[1;32m   5499\u001b[0m     )\n\u001b[1;32m   5500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5501\u001b[0m     \u001b[38;5;66;03m# Not a safetensors repo\u001b[39;00m\n\u001b[0;32m-> 5502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotASafetensorsRepoError(\n\u001b[1;32m   5503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a safetensors repo. Couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAFETENSORS_INDEX_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAFETENSORS_SINGLE_FILE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5504\u001b[0m     )\n",
      "\u001b[0;31mNotASafetensorsRepoError\u001b[0m: 'runwayml/stable-diffusion-v1-5' is not a safetensors repo. Couldn't find 'model.safetensors.index.json' or 'model.safetensors' files."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import get_safetensors_metadata\n",
    "\n",
    "metadata = get_safetensors_metadata(\"bigscience/bloomz-560m\")\n",
    "metadata\n",
    "metadata.files_metadata[\"model.safetensors\"].metadata\n",
    "\n",
    "metadata = get_safetensors_metadata(\"bigscience/bloom\")\n",
    "\n",
    "\n",
    "metadata\n",
    "len(metadata.files_metadata)\n",
    "\n",
    "get_safetensors_metadata(\"runwayml/stable-diffusion-v1-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
